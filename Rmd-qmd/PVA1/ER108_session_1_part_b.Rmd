---
title: "ER108 Session 3"
output: html_document
date: "2023-02-23"
author: "Anastasija Tetereva, PhD"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd(".....")
library(dplyr)
library(ggplot2)
```

## Comparing two (independent) population means
### ZixIt Corp. v. Visa USA Inc.

The National Law Journal (Aug. 26–Sep. 2, 2002) reported on an interesting court case involving ZixIt Corp., a start-up Internet credit card clearing center. ZixIt claimed that its new online credit card processing system would allow Internet shoppers to 
make purchases without revealing their credit card numbers. This claim violated the established protocols of most major credit card companies, including Visa. Without the company’s knowledge, a Visa vice president for technology research and development began writing emails and Web site postings on a Yahoo! message board for ZixIt investors, challenging ZixIt’s claim and urging investors to sell their ZixIt stocks. The Visa executive posted more than 400 emails and notes before he was caught. Once it was discovered that a Visa executive was responsible for the postings, ZixIt filed a lawsuit against Visa Corp., alleging that Visa—using the executive as its agent—had engaged in a ''malicious two-part scheme to disparage and interfere with ZixIt'' and its efforts to market the new online credit card processing system. In the libel case ZixIt asked for 699 million in damages. Dallas lawyers Jeff Tillotson and Mike Lynn, of the law firm Lynn, Tillotson & Pinker, were hired to defend Visa in the lawsuit. The lawyers, in turn, hired Dr. James McClave as their expert statistician. McClave testified in court on an ''event study'' he did matching the Visa executive’s email postings with movement of ZixIt’s stock price the next business day. McClave’s testimony, showing that there was an equal number of days when the stock went up as went down after a posting, helped the lawyers representing Visa to prevail in the case.
The National Law Journal reported that, after two-and-a-half days of deliberation, “the jurors found [the Visa executive] was not acting in the scope of his employment and that Visa had not defamed ZixIt or interfered with its business.”

The data were collected daily from September 1 to December 30, 1999 (an 83-day period) and are available in the ZIXVSA file. In addition  to daily closing price (dollars) of ZixIt stock, the file contains a variable for whether or not the Visa executive posted an email and the change in price of the stock the following business day. During the 83-day period, the executive posted email on 43 days and had no postings on 40 days.

If the daily postings by the Visa executive had a negative impact on ZixIt stock, then the average price change following nonposting days should exceed the average price change following posting days. Consequently, one way to analyze the data is to conduct 
a comparison of two population means through either a confidence interval or a test of hypothesis. Here, we let $\mu_1$ represent the mean price change of ZixIt stock following all nonposting days and $\mu_2$ represent the mean price change of ZixIt stock following posting days. If, in fact, the charges made by ZixIt are true, then m1 will exceed m2. However, if the data do not support ZixIt’s claim,  then we will not be able to reject the null hypothesis $H_0: \mu_1-\mu_2 = 0$ in favor of $H_1: \mu_1 - \mu_2 >0$. Similarly, if a confidence interval for $\mu_1-\mu_2$ covers the value 0, then there will be no evidence to support ZixIt’s claim. Because both sample sizes ($n_1 = 40$ and $n_2 = 43$) are large, we can apply the large sample $z$-test or large-sample confidence interval procedure for independent samples. 

```{r}
visa.data <- read.delim("ZIXVSA.txt")
summary(visa.data)
#install.packages("psych"); 
library(psych)
describe(visa.data)
```
```{r}
describeBy(visa.data$Change, visa.data$Posting)
```
```{r}
visa.data %>% ggplot(aes(x = Change, fill = Posting)) + geom_histogram(bins = 50)
```

```{r}
visa.data %>% ggplot(aes(x = Change, y = Posting)) + 
  geom_boxplot()
```
```{r}
t.test(Change ~ Posting, data = visa.data, alternative = "greater")
```

Both the 95% confidence interval and $p$-value for a two-tailed test of hypothesis are highlighted on the printout. Note that the 95% confidence interval, (-0.13, 0.06), covers the value 0, and the $p$-value of 0.6166 implies that the two population means are not significantly different. Also, interestingly, the sample mean price change after posting days ($\overline{x}_1$ = 0.06) is small and positive, while the sample mean price change after nonposting days ($\overline{x}_1$ = - 0.13) is small and negative, totally contradicting ZixIt’s claim. The statistical expert for the defense presented these results to the jury, arguing that the ''average price change following posting days is small and similar to the average price change following nonposting days'' and ''the difference in the means is not statistically significant.''

### Nonparametric test for comparing two population means (bootstrap)
```{r}

Boot.runs <- 20000 # number of Bootstrap runs

visa.data.with.post <- visa.data  %>%
                       filter(Posting == "POST")
                   
visa.data.without.post <- visa.data  %>%
                          filter(Posting == "NO")

n.yes <- length(visa.data.with.post) 
n.no <- length(visa.data.without.post) 

boot.samples.yes = matrix(sample(visa.data.with.post$Change, size = Boot.runs * n.yes, 
                              replace = TRUE),
                              Boot.runs, n.yes)
boot.samples.no = matrix(sample(visa.data.without.post$Change, size = Boot.runs * n.no, 
                              replace = TRUE),
                              Boot.runs, n.no)

test.statistics <- apply(boot.samples.no,1,mean) - apply(boot.samples.yes,1,mean)

hist(test.statistics, main = "Bootstrap Distribution", xlab = "")
quantile(test.statistics, c(0.025, 0.975))
```
### Nonparametric test for comparing two population means (permutation test)
original <- diff(tapply(outcome, treatment, mean))
mean(outcome[treatment==1])-mean(outcome[treatment==0])

#Permutation test
To compare outcomes in experiments, we often use Student’s $t$-test. It assumes that data are randomly selected from the population, arrived in large samples (>30), or normally distributed with equal variances between groups. If we do not happen to meet these assumptions, we may use one of the simulation tests. For example, the Permutation Test.

Rather than assuming underlying distribution, the permutation test builds its distribution, breaking up the associations between or among groups. Often we are interested in the difference of means or medians between the groups, and the null hypothesis is that there is no difference there. We may ask the question: from all the possible permutations, how extreme our data would look like? All possible permutations would represent a theoretical distribution. In practice, there is no need to perform ALL permutations to build the theoretical distribution, but run a reasonable number of simulations to take a sample from that distribution. 


The Permutation test is a powerful tool in measuring effects in experiments. It is easy to implement, and it does not rely on many assumptions as other tests do. It has not been widely popular until the simulation on computers became routinely implemented.

It is closely related to the other simulation test: the bootstrapping hypothesis test, where the samples are drawn with replacement.


```{r}
permutation.test <- function(treatment, outcome, n){
  data <- na.omit(data.frame(treatment, outcome))
  treatment <- data[,1]
  outcome <- data[,2]
  distribution=c()
  result=0
  for(i in 1:n){
    
    distribution[i]= diff(by(outcome, sample(treatment, length(treatment), FALSE), mean))
  }
  original <- diff(by(outcome, treatment, mean))
  return(list(distribution, original))
}

treatment <- visa.data$Posting
outcome <-  visa.data$Change
test.statistics.permut <- permutation.test(visa.data$Posting, visa.data$Change, 10000)
hist(test.statistics.permut[[1]], breaks=50, col='grey', main="Permutation Distribution", las=1, xlab='')
abline(v=test.statistics.permut[[2]], lwd=3, col="red")
quantile(test.statistics.permut[[1]], c(0.025, 0.975))
```
We run a simulation drawing 10k shaffles without replacement, and record the difference in means for each permutation. Then we construct confidence intervals for the mean difference under the null hypothesis that there is no difference in the mean value of change. If we plot the distribution, we may observe that our original difference is not particularly extreme, with an exact $p$-value of ? (we looked at the confidence intervals, try to compute $p$-value now). If we compare this $p$-value with the one of $t$-test, what do we observe?

R also has several libraries to run permutation tests. One of them is library(coin). To use this library, "treatment" variable should be stored as a factor object rather than a character object.
```{r}
#install.packages("coin")
library(coin)
visa.data$Posting = as.factor(visa.data$Posting )
oneway_test(Change~Posting,data=visa.data,distribution="exact")
```
### Finding an appropriate sample size

You can find the appropriate sample size to estimate the difference between a pair of 
parameters with a specified sampling error (SE) and degree of reliability. To estimate the difference between a pair of 
parameters correct to within SE units with the given confidence level.

Consider the following problem. New fertilizer compounds are often advertised with the promise of increased 
crop yields. Suppose we want to compare the mean yield $m_1$ of wheat when a new fertilizer is used with the mean yield $m_2$ with a fertilizer in common use. The estimate of the 
difference in mean yield per acre is to be correct to within $.25$ bushel with a confidence 
coefficient of $.95$. If the sample sizes are to be equal, find $n_1 = n_2 = n$, the number of 
1-acre plots of wheat assigned to each fertilizer.

To solve the problem, you need to know something about the variation in 
the bushels of yield per acre. Suppose from past records you know the yields of wheat 
possess a range of approximately 10 bushels per acre. You could then approximate 
$\sigma_1 = \sigma_2 = \sigma$ by letting the range equal $4 \sigma$. We know that $z_{\alpha/2}\sigma_{\overline{x}_1-\overline{x}_2} = SE$. This way, $z_{\alpha/2}\sqrt{\frac{\sigma_1^2}{n_1} +\frac{\sigma_2^2}{n_2}} = SE$ and $1.96 \sqrt{\frac{2 (2.5)^2}{n}} = 0.25$ and $n = 769$.

### Comparing two population proportions

We 
demonstrated how the expert statistician used a comparison of two 
means to defend Visa in a libel case. Recall that ZixIt claimed that a Visa executive’s 
email postings had a negative impact on ZixIt’s attempt to develop a new online credit 
card processing system. Here, we demonstrate another way to analyze the data, one successfully presented in court by the statistician.
In addition to daily closing price and trading volume of ZixIt stock, the ZIXVSA file 
also contains a qualitative variable that indicates whether the stock price increased or not 
(decreased or stayed the same) on the following day. This variable was created by the statistician to compare the proportion of days on which ZixIt stock went up for posting and nonposting days. Let $p_1$ represent the proportion of days where the ZixIt stock price increased  following all nonposting days and $p_2$ represent the proportion of days where the ZixIt 
stock price increased following posting days. Then, if the charges made by ZixIt were true 
(i.e., that postings had a negative impact on ZixIt stock), $p_1$ will exceed $p_2$. Thus, a comparison of two population proportions is appropriate. Recall that during the 83-day period 
of interest, the executive posted emails on 43 days and had no postings on 40 days. Again, 
both sample sizes ($n_1 = 40$ and $n_2 = 43$) are large, so we can apply the large-sample $z$-test 
or large-sample confidence interval procedure for independent samples. 
```{r}
#table(visa.data$Up.Down,visa.data$Posting)
prop.test(length(visa.data$Up.Down[visa.data$Up.Down=="UP"]), nrow(visa.data), p = 0.5, alternative = "two.sided")
```

From the printout you can see that following the .. nonposting days, the price 
increased on .. days; following the ... posting days, the stock price increased on ... days. 
Thus, the sample proportions are $p_1 = $ and $p_2 = $. Are these 
sample proportions different enough for us to conclude that the population proportions 
are different and that ZixIt’s claim was true? Not according to the statistical analysis. 
Note that the 95% confidence interval $(0.34, 0.56)$, includes the value 
0.5, and the $p$-value for the two-tailed test of $H_0: p_1 = 0.5$ is $0.445$, exceeds, 
say, $\alpha = 0.05$. Both imply that the two population proportions are not significantly different.


## Comparing two dependent population means

Suppose you want to compare the mean daily sales of two restaurants located in the 
same city. If you were to record the restaurants’ total sales for each of 12 randomly 
selected days during a 6-month period, the results might appear as in the restaurants.txt file. 

Do these data provide evidence of a difference between the mean daily sales of the two 
restaurants? We want to test the null hypothesis that the mean daily sales, $\mu_1$ and $\mu_2$, for the two 
restaurants are equal against the alternative hypothesis that they differ; that is,
$H_0: \mu_1-\mu_2 = 0$
$H_a: \mu_1-\mu_2 \neq 0$
Many researchers mistakenly use the $t$-statistic for two independent samples to conduct this test. t = .38, is highlighted on the printout, as well as the $p$-value of the test. At $\alpha = .10$, the $p$-value exceeds $\alpha$. Thus, from this analysis we might conclude that insufficient evidence exists to infer that there is a difference in mean daily 
sales for the two restaurants.
If you carefully examine the data, however, you will find this conclusion difficult to accept. The sales of restaurant 1 exceed those of restaurant 2 for every  one of the randomly selected 12 days. This, in itself, is strong evidence to indicate that 
$\mu_1$ differs from $\mu_2$, and we will subsequently confirm this fact. Why, then, was the $t$-test 
unable to detect this difference? The answer is, the independent samples $t$-test is not a 
valid procedure to use with this set of data.
The $t$-test is inappropriate because the assumption of independent samples is 
invalid. We have randomly chosen days; thus, once we have chosen the sample of 
days for restaurant 1, we have not independently chosen the sample of days for restaurant 2. The dependence between observations within days can be seen by examining the pairs of daily sales, which tend to rise and fall together as we go from day 
to day. This pattern provides strong visual evidence of a violation of the assumption 
of independence required for the two-sample $t$-test. Also, there is a large variation within samples in 
comparison with the relatively small difference between the sample means. Because the variation
is so large, the $t$-test ois unable to detect a possible difference between $\mu_1$ and $\mu_2$.

We now consider a valid method of analyzing the data. We add the column of differences between the daily sales of the two restaurants, $x_d = x_1 - x_2$. We can regard these daily differences in sales as a random 
sample of all daily differences, past and present. Then we can use this sample to make 
inferences about the mean of the population of differences, which is equal to the 
difference $\mu_1-\mu_2$, that is, the mean of the population (and sample) of differences equals the difference between the population (and sample) means. 

 

```{r}
library("readxl")
#now should work
data.rest <- read_excel("SALES2.xlsx")
head(data.rest)
```
Now we will run two versions of the $t$-test. First, we run $t$-test for the difference between the sales of two restaurants with the null hypothesis that the difference is equal to zero and alternative that it's larger than zero.
```{r}
t.test(data.rest$SALES1-data.rest$SALES2, mu = 0, alternative = "greater")
```
Second, we run a $t$-test for paired samples with the null hypothesis that both restaurants have the same revenue and alternative that the first restaurant's revenue is larger. Compare results of both tests.

```{r}
t.test(data.rest$SALES1, data.rest$SALES2, paired = TRUE, alternative = "greater")
```

Given that you are an experienced data scientist, you might want to compare your asymptotic results to those of bootstrap and permutation test. Please do so.