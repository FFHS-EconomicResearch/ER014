---
title: "ER108 Session 4"
output: html_document
author: "Anastasija Tetereva, PhD"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
```

## ANOVA
### Improving driving performance while fatigued


Long-haul  truck drivers are often asked to drive while fatigued. Can a secondary task—such as a word association task—improve 
the performance of a fatigued driver? This was the question of interest in a Human Factors (May 2014) study. The researchers used a driving simulator to obtain their data. Each of 40 college students was assigned to drive a long distance in the simulator. However, the student-drivers were divided into four groups of 10 drivers each. Group 1 performed the verbal task continuously (continuous verbal 
condition); Group 2 performed the task only at the end of the drive (late verbal condition); Group 3 did not perform the task at all (no verbal condition); and, Group 4 listened to a program on the car radio (radio show condition). At the end of the simulated drive, drivers were asked to recall billboards that they saw along the way. The percentage of billboards recalled by each student-driver is provided in the data below. Determine if  the mean recall percentage differs for student-drivers in the four groups.

```{r}
library("readxl")
data.fatigue <- read_excel("FATIGUE.xlsx")
head(data.fatigue)
```

#### To do's
- Inspect the data
- Compute the mean, median, and standard deviation for the percentage of billboards in every group of student-drivers
- Create boxplots for the percentage of billboards for every group of student drivers
- Create histogram for the percentage of billboards for every group of student drivers
- Create qqplot to visually justify if the data come from the Gaussian distribution
- Perform a test to test the null hypothesis of data coming from the Gaussian distribution
- What can you tell about the means and the variances? Are they the same for all groups? Or are there some groups that are different?

#### Hypothesis of equal variances
Before running ANOVA, one should test the hypothesis of equal variances. It can be done with the following tests:

- Bartlett’s test: Compare the variances of two or more groups. The data must be normally distributed.
- Levene’s test: A robust alternative to the Bartlett’s test that is less sensitive to departures from normality.
_ Fligner-Killeen’s test: a non-parametric test which is very robust against departures from normality.



```{r}
res <- bartlett.test(RECALL ~ GROUP, data = data.fatigue)
res
```

From the output, it can be seen that the $p$-value of 0.4387 is not less than the significance level of 0.05. This means that there is no evidence to suggest that the variance in plant growth is statistically significantly different for the three treatment groups.

```{r}
library(car)
# Levene's test with one independent variable
leveneTest(RECALL ~ GROUP, data = data.fatigue)
```
From the output, it can be seen that the $p$-value of 0.5949 is not less than the significance level of 0.05. This means that there is no evidence to suggest that the variance in plant growth is statistically significantly different for the three treatment groups.

The Fligner-Killeen’s test is one of the many tests for homogeneity of variances which is most robust against departures from normality.

```{r}
fligner.test(RECALL ~ GROUP, data = data.fatigue)
```

- What is the conclusion according to Fligner-Killeen’s test?

```{r}
anova.test <- aov(RECALL ~ GROUP, data = data.fatigue)
summary(anova.test)
```
The model summary first lists the independent variables being tested in the model (in this case we have only one, ‘GROUP’) and the model residuals (‘Residual’). All of the variation that is not explained by the independent variables is called residual variance.

The rest of the values in the output table describe the independent variable and the residuals:

The **Df** column displays the degrees of freedom for the independent variable (the number of levels in the variable minus 1), and the degrees of freedom for the residuals (the total number of observations minus one and minus the number of levels in the independent variables).

The **Sum Sq** column displays the sum of squares (a.k.a. the total variation between the group means and the overall mean).
The Mean Sq column is the mean of the sum of squares, calculated by dividing the sum of squares by the degrees of freedom for each parameter.

The **F value** column is the test statistic from the F test. This is the mean square of each independent variable divided by the mean square of the residuals. The larger the F value, the more likely it is that the variation caused by the independent variable is real and not due to chance.

The **Pr(>F)** column is the p value of the F statistic. This shows how likely it is that the F value calculated from the test would have occurred if the null hypothesis of no difference among group means were true.
The $p$-value of the GROUP variable is low (p < 0.001), so it appears that the type of GROUP has a real impact on the percentage of billboards the driver could remember.

To check whether the model fits the assumption of homoscedasticity, look at the model diagnostic plots in R using the plot() function:

```{r}
plot(anova.test)
```

The diagnostic plots show the unexplained variance (residuals) across the range of the observed data.

Each plot gives a specific piece of information about the model fit, but it’s enough to know that the red line representing the mean of the residuals should be horizontal and centered on zero (or on one, in the scale-location plot), meaning that there are no large outliers that would cause research bias in the model.

The normal qqplot plot plots a regression between the theoretical residuals of a perfectly-homoscedastic model and the actual residuals of your model, so the closer to a slope of 1 this is the better. This qqplot plot is very close, with only a bit of deviation. From these diagnostic plots we can say that the model does not contradict the assumption of homoscedasticity.

If your model doesn’t fulfill the assumption of homoscedasticity, you can try the Kruskall-Wallis test instead. Or run bootstrap.

ANOVA tells us if there are differences among group means, but not what the differences are. To find out which groups are statistically different from one another, you can perform a Tukey’s Honestly Significant Difference (Tukey’s HSD) post-hoc test for pairwise comparisons:

```{r}
tukey.anova.test<-TukeyHSD(anova.test)
tukey.anova.test
```


```{r}
plot(tukey.anova.test, las = 1)
```
If some assumptions are not fulfilled or the sample size is too small, it is recommended to use bootstrap ANOVA.

```{r}
library(lmboot)
anova.boot <- ANOVA.boot(RECALL ~ GROUP, data = data.fatigue)
anova.boot$`p-values`
```
- Perform a bootstrap test to compare the mean values in the following groups: LateVerb-ContVerb
- Perform a permutation test to compare the mean values in the following groups: LateVerb-ContVerb

## Two-way ANOVA
### Consumer reviews

'Just-world' theory proposes that people receive the rewards and/or punlishments that they deserve. Marketing researchers examined just-world theory in the context of fair trade (Journal of Marketing, January 2012). In particular, the researchers wanted to know if manipulating market conditions has an impact on whether consumers purchase fair-trade products. A designed experiment with two manipulated market factors was employed. One factor was justice reparation potential (low or high); a second factor was producer need (moderate or high). A sample of business students was divided into four groups—34 students were randomly assigned to each of 
the 2 * 2 = 4 market condition treatments. After reading a news article and press release that manipulated their condition, students reported on their intention to purchase a fair-trade product. Intention was measured on a scale ranging from 0 to 6 points. The data for all 136 students (simulated based on information provided in the journal article) are saved in the accompanying 
file.

```{r}
library("readxl")
data.ftrade <- read_excel("FTRADE.xlsx")
head(data.ftrade)
```
```{r}
interaction.plot(x.factor = data.ftrade$NEED, trace.factor = data.ftrade$JRP,
                 response = data.ftrade$INT, fun = mean,
                 type = "b", legend = TRUE,
                 xlab = "NEED", ylab="INT",
                 pch=c(1,19), col = c("#00AFBB", "#E7B800"))
```
To determine the nature of the treatment effect, if any, on the response in a factorial experiment, we need to break the treatment variability into three components:  Interaction between Factors A and B, Main Effect of Factor A, and Main Effect of 
Factor B. The Factor Interaction component is used to test whether the factors combine 
to affect the response, while the Factor Main Effect components are used to determine 
whether the factors separately affect the response. Figure above shows that the difference 
between mean distances between NEED varies with JRP. Thus, the effect of NEED on 
distance depends on JRP, and therefore the two factors do interact.

```{r}
boxplot(INT ~ NEED * JRP, data = data.ftrade, frame = FALSE,  col = c("#00AFBB", "#E7B800"), ylab="NEED")
```

```{r}
ftrade.aov <- aov(INT ~ NEED + JRP + NEED:JRP, data = data.ftrade)
summary(ftrade.aov)
```