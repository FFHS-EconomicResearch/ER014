---
title: "Data Science for Business"
subtitle: "Regression"
author: "Prof. Dr. J√∂rg Schoder"
institute: "FFHS" 
date: "`r Sys.Date()`"
bibliography: ../../lit/my_bib.bib
reference-section-title: Quellenverzeichnis
output:
  xaringan::moon_reader:
    self_contained: true
    css: 
         - default
         - ../../css/ffhs-theme_js.css
         - xaringan-themer.css
    includes:
      after_body: ../../css/insert-logo.html
    lib_dir: ../../libs
    nature:
      slideNumberFormat: "%current%/%total%"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
    seal: false
    

    
---
class: title-slide

```{r xaringan-themer, include=FALSE}
library(xaringanthemer)
style_xaringan(text_color = "#d50006",inverse_text_color = "#FFFFFF",inverse_background_color = "#d50006", title_slide_background_color = "#d50006",header_background_color = "#d50006",header_color = "#FFFFFF",header_h1_font_size = "32px",
  header_h2_font_size = "26px",link_color="#502479",
  header_h3_font_size = "20px",text_slide_number_color = "#d50006",text_slide_number_font_size = "0.5em")
```

```{r xaringanExtra, echo=FALSE}
xaringanExtra::use_progress_bar(color = "#d50006", location = "bottom")
xaringanExtra::use_xaringan_extra(c("tile_view","scribble","panelset","tachyons"))
xaringanExtra::style_panelset_tabs(font_family = "inherit")
#xaringanExtra::use_search(show_icon = TRUE)
#weitere: "share_again","animate_css", "webcam","freezeframe","clipboard","fit_screen","extra-styles" 
xaringanExtra::use_editable(expires = 1)
xaringanExtra::use_freezeframe(trigger = "hover")
``` 

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(latex2exp)
library(fontawesome)
source(xfun::from_root("lit","helper.R"))
library(RefManageR)
library(tidyverse)
library(gt)
BibOptions(check.entries = FALSE, 
           bib.style = "authoryear", 
           style = "markdown",
           dashed = TRUE)
file.name <- system.file("Bib", 
                         "my_bib.bib", 
                         package = "RefManageR")
bib <- ReadBib(xfun::from_root("lit","my_bib.bib"))
```

# ER014 - Data Science & Strategy for Business

## PVA2

### Teil 3: Stochastische Regressionsanalyse

 

<br>
<br>
<br>
<br>
<br>
<br>
<br>
### FS 2025
<br>
### Prof. Dr. J√∂rg Schoder
.mycontacts[
`r fa('github')` @FFHS-EconomicResearch
`r fa('linkedin')` @jfschoder
]


---
layout: true

<div class="my-footer"></div>       

<div style="position: absolute;left:400px;bottom:10px;font-size:9px">`r fa('creative-commons')``r rmarkdown::metadata$author`</div>


---
name: agenda
class: left

.blockquote[Agenda]

## Stochastische Regressionsanalyse

* Intro

* Regressionsanalyse mit Resampling-Methode

* Regressionsanalyse im traditionellen Ansatz
  
* Regressionsdiagnostik im traditionellen Ansatz




---
class: left

.blockquote[Intro]

## Grundidee stochastische Regressionsanalyse

.panelset[
.panel[.panel-name[Stichprobe1]
```{r}
#| echo: false
#| message: false
#| out-width: '55%'
#| fig-align: 'center'
library(tidyverse)
## Import data -----
my_in_file <- "autos_(StockerUIBK)_20240414.csv"
tbl_autos <- read_csv2(xfun::from_root("data","raw",my_in_file))
## Dataviz ------
p <- tbl_autos %>% 
          ggplot(aes(x=Alter,y=Preis)) + 
              geom_point(alpha=.5,size=.8) + theme_light() + 
              geom_smooth(method = "lm", se = FALSE) +
              scale_x_continuous(limits=c(0,6),breaks=seq(0, 5, 1)) +
              scale_y_continuous(limits=c(0,26000),breaks=seq(0, 25000, 5000)) + 
              labs(x="Alter (in Jahren)",y="Preis",title="Gebrauchtwagen")
## Regressionsgerade gesamt -----
p <- p + geom_smooth(method = "lm", se = FALSE) 

## Stichproben ziehen ------
### Stichprobe 1 -----
set.seed(23)
tbl_autos_sub1 <- tbl_autos %>% 
                      sample_n(size=7,replace=FALSE)

p_sub1 <- p +  geom_point(data=tbl_autos_sub1, color="#d50006",size=1.2) +
              geom_smooth(data=tbl_autos_sub1, color="#d50006",method = "lm", se = FALSE)
p_sub1
```
]
.panel[.panel-name[Stichprobe 2]
```{r}
#| echo: false
#| message: false
#| out-width: '55%'
#| fig-align: 'center'
### Stichprobe 2 -------
tbl_autos_sub2 <- tbl_autos %>% 
                     slice(c(13,18,21,25))
# Regressionsmodell auf die Subdaten
model_sub2 <- tbl_autos_sub2 %>% lm(Preis ~ Alter, data = .)

# Daten f√ºr die Regressionsgerade im gew√ºnschten Bereich (xlim(1.8, 3.4)) berechnen
x_vals <- seq(1.8, 3.4, length.out = 100)  # 100 Werte im x-Bereich
y_vals <- predict(model_sub2, newdata = data.frame(Alter = x_vals))  # Vorhersage der y-Werte

# Datenrahmen f√ºr geom_line() erstellen
line_data <- data.frame(Alter = x_vals, Preis = y_vals)

# Plot
p_sub1 + 
  geom_point(data = tbl_autos_sub2, aes(color = "#502479"), show.legend = FALSE,size=1.2) +  # Punkte ohne Legende
  geom_line(data = line_data, aes(x = Alter, y = Preis), color = "#502479") +  # Regressionsgerade
  scale_color_manual(values = "#502479") 
```

]
.panel[.panel-name[Code Sampling]
```{r}
#| echo: true
#| eval: false
#| message: false
library(tidyverse)
## Import data -----
my_in_file <- "autos_(StockerUIBK)_20240414.csv"
tbl_autos <- read_csv2(xfun::from_root("data","raw",my_in_file))
p <- tbl_autos %>% 
      ggplot(aes(x=Alter,y=Preis)) + geom_point() 
## Stichproben ziehen ------
### Stichprobe 1 -----
set.seed(23)
tbl_autos_sub1 <- tbl_autos %>% 
                      sample_n(size=7,replace=FALSE)
### "Stichprobe" 2 -------
tbl_autos_sub2 <- tbl_autos %>% 
                     slice(c(13,18,21,25))
```
]
.panel[.panel-name[Code Diagramm]
```{r}
#| echo: true
#| eval: false
#| message: false
## Streudiagramm ----
###  Regressionsgerade gesamt -----
p <- p + geom_smooth(method = "lm", se = FALSE) 
###  Stichproben erg√§nzen -----
p + geom_point(data=tbl_autos_sub1, 
               color="#502479") +
    geom_smooth(data=tbl_autos_sub1,
                color="#502479",method = "lm", 
                se = FALSE) + 
    geom_point(data=tbl_autos_sub2, 
               color="#d50006") +
    geom_smooth(data=tbl_autos_sub2,
                color="#d50006",method = "lm", 
                se = FALSE)
```
]
]

.quelle[Eigene Darstellung.]




---
class: left

.blockquote[Intro]

## Wiederholung PVA1: m√∂gliche Punktsch√§tzer

<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:table-ch8"></span>M√∂gliche Punktsch√§tzer auf Basis von Stichproben
</caption>
<thead>
<tr>
<th style="text-align:right;">
Fall
</th>
<th style="text-align:left;">
Parameter der Grundgesamtheit
</th>
<th style="text-align:left;">
Notation
</th>
<th style="text-align:left;">
Punktsch√§tzung
</th>
<th style="text-align:left;">
Symbol(e)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;width: 0.5in; ">
1
</td>
<td style="text-align:left;width: 1.2in; ">
Anteil in Grundgesamtheit
</td>
<td style="text-align:left;width: 0.8in; ">
<span class="math inline">\(p\)</span>
</td>
<td style="text-align:left;width: 1.5in; ">
Anteil in Stichprobe
</td>
<td style="text-align:left;width: 0.6in; ">
<span class="math inline">\(\widehat{p}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
2
</td>
<td style="text-align:left;width: 1.2in; ">
Mittelwert der Grundgesamtheit
</td>
<td style="text-align:left;width: 0.8in; ">
<span class="math inline">\(\mu\)</span>
</td>
<td style="text-align:left;width: 1.5in; ">
Stichprobenmittelwert
</td>
<td style="text-align:left;width: 0.6in; ">
<span class="math inline">\(\overline{x}\)</span> oder <span class="math inline">\(\widehat{\mu}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
3
</td>
<td style="text-align:left;width: 1.2in; ">
Differenz von Anteilen einer Grundgesamtheit
</td>
<td style="text-align:left;width: 0.8in; ">
<span class="math inline">\(p_1 - p_2\)</span>
</td>
<td style="text-align:left;width: 1.5in; ">
Differenz von Anteilen einer Stichprobe
</td>
<td style="text-align:left;width: 0.6in; ">
<span class="math inline">\(\widehat{p}_1 - \widehat{p}_2\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
4
</td>
<td style="text-align:left;width: 1.2in; ">
Differenz von Mittelwerten der Grundgesamtheit
</td>
<td style="text-align:left;width: 0.8in; ">
<span class="math inline">\(\mu_1 - \mu_2\)</span>
</td>
<td style="text-align:left;width: 1.5in; ">
Differenz von Stichprobenmittelwerten
</td>
<td style="text-align:left;width: 0.6in; ">
<span class="math inline">\(\overline{x}_1 - \overline{x}_2\)</span> oder <span class="math inline">\(\widehat{\mu}_1 - \widehat{\mu}_2\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
5
</td>
<td style="text-align:left;width: 1.2in; ">
Empirischer Regressionskoeffizient (Grundgesamtheit)
</td>
<td style="text-align:left;width: 0.8in; ">
<span class="math inline">\(\beta_1\)</span>
</td>
<td style="text-align:left;width: 1.5in; ">
Angepasster ("fitted") Regressionskoeffizient (Stichprobe)
</td>
<td style="text-align:left;width: 0.6in; ">
<span class="math inline">\(b_1\)</span> oder <span class="math inline">\(\widehat{\beta}_1\)</span>
</td>
</tr>
</tbody>
</table>



.quelle[vgl. `r Cite(bib,"ismay_statistical_2024")`]




---
class: inverse, center, middle

## Regressionsanalyse mit der Resampling-Methode

.blockquote[Bootstrapping-Verteilung und Konfidenzintervall]

.blockquote[Signikanz des Steigungsparameters]



---
class: left

.blockquote[Bootstrapping-Verteilung und Konfidenzintervall]

## Punktsch√§tzer und Bootstrapping-Verteilung mit der **infer**-Pipe

.panelset[
.panel[.panel-name[Koeffizient]
* Modell (**ein** numerischer Regressor):

$$\begin{eqnarray}
\widehat{\mbox{Preis}}&=&\hat\beta_1 + \hat\beta_2\cdot \mbox{Alter}\\
\end{eqnarray}$$

* **infer**-Pipe zur Ermittlung des Steigunskoeffizienten

```{r}
#| echo: true
library(infer)
obs_slope <- tbl_autos %>%
                specify(Preis ~ Alter) %>% calculate(stat = "slope")
```
```{r}
#| echo: false
obs_slope
```

]
.panel[.panel-name[Konfidenzintervall]
* Bootstrapping-Verteilung des Koeffizienten

```{r}

### Bootstrapping-Verteilung des Koeffizienten ----
boot_dist <-tbl_autos %>%
                specify(Preis~Alter) %>%
                generate(reps = 1000, type = "bootstrap") %>%
                calculate(stat = "slope")

```
]
.panel[.panel-name[Diagramm]
```{r}
#| echo: true
#| message: false
#| out-width: '45%'
#| fig-align: 'center'
visualize(boot_dist)
```

]
]

---
class: left

.blockquote[Bootstrapping-Verteilung und Konfidenzintervall]

## Konfidenzintervalle im Vergleich

.panelset[
.panel[.panel-name[Perzentilmethode]
```{r}
percentile_ci <- boot_dist %>%
                        get_confidence_interval(type = "percentile",
                                                level = 0.95)
percentile_ci
```
]
.panel[.panel-name[Standardfehler-Methode]
```{r}
se_ci <- boot_dist %>%
            get_confidence_interval(type = "se",
                                    point_estimate = obs_slope,
                                    level = 0.95)
se_ci
```

]
.panel[.panel-name[Diagramm]
```{r}
#| echo: true
#| message: false
#| out-width: '33%'
#| fig-align: 'center'
visualize(boot_dist) +
  shade_confidence_interval(endpoints = percentile_ci, fill = NULL,
                            linetype = "solid",color = "dodgerblue2") +
  shade_confidence_interval(endpoints = se_ci, fill = NULL,
                            linetype = "dashed",color = "dodgerblue3")
```
```{r}
#| echo: false
p_ci <- visualize(boot_dist) +
            shade_confidence_interval(endpoints = percentile_ci, fill = NULL,
                                      linetype = "solid",color = "dodgerblue2") +
            shade_confidence_interval(endpoints = se_ci, fill = NULL,
                                      linetype = "dashed",color = "dodgerblue3")
```

]
]


???

sehr √§hnlich, keines enth√§lt Null. Legt signifikant negativen Koeffizienten nahe


---
class: left

.blockquote[Signikanz des Steigungsparameters]

## Konfidenzintervalle im Vergleich

.panelset[
.panel[.panel-name[Null-Verteilung]
```{r}
null_dist <-tbl_autos %>%
              specify(Preis~Alter) %>%
              hypothesize(null="independence") %>% #Nullhypothese als zus√§tzliches Element der Pipe
              generate(reps = 1000, type = "permute") %>%  # permute statt bootstrap
              calculate(stat = "slope")
null_dist %>%
  get_p_value(obs_stat = obs_slope,direction = "less")
```

]
.panel[.panel-name[Diagramm]
```{r}
#| echo: true
#| message: false
#| out-width: '40%'
#| fig-align: 'center'
null_dist %>% visualize() +   # Verteilung um Null! - wg. $H_0:~\beta_1=0$
                  shade_p_value(obs_slope,
                                direction = "less")
```

]
]


???

* Optionen der `hypothesize()`-Funktion:
    * "independence" (bivariat) 
    * "point" (univariat, unabh√§ngige Stichprobe (independent measures)) und 
    * "paired independence" (univariat, abh√§ngige Stichproben (repeated measures))




---
class: inverse, center, middle

## Regressionsanalyse im traditionellen Ansatz 


.blockquote[Koeffizienten und t-Test]

.blockquote[Modellg√ºte und F-Test]

.blockquote[Modellauswahl]


???

auf Basis theoretischer Verteilungen


---
class: left

.blockquote[Koeffizienten und t-Test]

## Regressionstabelle und Ergebnis-Vergleich mit Resampling-Methodik


.panelset[
.panel[.panel-name[Anpassung]

```{r}
#| echo: true
library(moderndive) # f√ºr get_regression_()`-Funktionen - Ausgabe im tidy-Format
# Fit regression model:
reg_auto <- tbl_autos %>%
                lm(Preis~Alter,.)
reg_auto %>%
  get_regression_table() %>% 
  gt()
```
]
.panel[.panel-name[Vergleich]
* Quantitative √úbereinstimmung des Sch√§tzwerts f√ºr den Koeffizienten $\beta_2$ mit `obs_slope` aus der **infer**-Pipe: $\hat\beta_2=`r round(get_regression_table(reg_auto)$estimate[2],2)`$

* Was ist mit den weiteren Spalten?
  * Standardfehler der Punktsch√§tzer
  * t-Wert der Punktsch√§tzer
  * p-Wert zum t-Test $(H_0: \beta_2=0$, $H_A: \beta_2\neq0)$ 
  * Konfidenzintervalle der Koeffizienten
]
.panel[.panel-name[Konfidenzintervalle]
```{r}
#| echo: false
#| message: false
#| out-width: '55%'
#| fig-align: 'center'
lo_ci <- reg_auto %>%
            get_regression_table() %>%
            select(term,lower_ci) %>%
            filter(term=="Alter") %>%
            pull()
up_ci <- reg_auto %>%
              get_regression_table() %>%
              select(term,upper_ci) %>%
              filter(term=="Alter") %>%
              pull()
trad_ci <- c(lo_ci,up_ci)

p_ci + shade_confidence_interval(endpoints = se_ci, fill = NULL,
                                 linetype = "dotted", color = "#502479")
```

]
]

???

* Anpassung? `r fa('circle-right')` **an die Daten**
* Hinweis moderndive:
  * `get_regression_table()`: Tabelle mit Sch√§tzwerten und Statistiken zu den Koeffizienten wie abgebildet 
  * `get_regression_points()`: Tabelle mit Beobachtungen, Vorhergesagten Werten und Residuen
  * `get_regression_summaries()`: Tabelle mit Statistiken zum Modell (u.a. $R^2$, F-Wert etc.)
* Standardfehler
  * allg: Standardabweichung der Stichprobenverteilung eines Punktsch√§tzers, dessen Wert f√ºr eine Stichprobe berechnet wird.
  * hier: bezogen auf Koeffizienten


---
class: left

.blockquote[Koeffizienten und t-Test]

## Standardfehler der Punktsch√§tzer

* Allgemein: Standardfehler als Standardabweichung der Stichprobenverteilung eines Punktsch√§tzers
  * hier also: im Beispiel k√∂nnen wir eine Variation der Steigungsparamter von `r round(get_regression_table(reg_auto)$std_error[2],2)` Euro erwarten
  * Somit: Mass f√ºr die Variation der angepassten Koeffizienten `r fa('circle-right')` entscheidender Wert f√ºr die **Reliabilit√§t** (vgl. t-Test)

* Koeffizient $\hat\beta_2=`r round(get_regression_table(reg_auto)$estimate[2],2)`$ (Steigungsparameter) minimiert f√ºr die vorliegende Stichprobe die Fehlerquadratsumme.

* F√ºr alternative Stichprobe (aus derselben Grundgesamtheit) w√ºrde h√∂chstwahrscheinlich ein anderer Wert f√ºr $\hat\beta_2$ die Fehlerquadratsumme minimieren (`r fa('circle-right')` **Stichprobenvariabilit√§t**).
  
* Zur Erinnerung: **Bootstrapping**-Verteilung als Approximation dieser Stichprobenverteilung

???

* Standarfehler:  im Beispiel k√∂nnen wir eine Variation der Steigungsparamter von `r round(get_regression_table(reg_auto)$std_error[2],2)` Euro erwarten


Recall from Subsection 8.7.1 that the bootstrap distribution is an approximation to the sampling distribution in that they have a similar shape. Since they have a similar shape, they have similar standard errors. However, **unlike the sampling distribution, the bootstrap distribution is constructed from a single sample**, which is a practice **more aligned with what‚Äôs done in real life**.



---
class: left

.blockquote[Koeffizienten und t-Test]

## Standardfehler und t-Test 

.panelset[
.panel[.panel-name[Einordnung]

* `r fa('r-project')` verwendet den Standardfehler 
  * ...zur Berechnung der Konfidenzintervalle und...
  * ...f√ºr die Durchf√ºhrung des t-Tests, ob der jeweilige **Koeffizient** sich signifikant von Null unterscheidet:

$$H_0: ~\beta_1=0~~~\mbox{vs.}~~~H_A: ~\beta_1\neq 0$$

* Obs! Zweiseitiger Hypothesentest!

* traditioneller vs. randomisierter t-Test
]
.panel[.panel-name[Teststatistik]
* theoriebasierter (!) Standardfehler des angepassten Koeffizienten $b_1$:

$$\mbox{SE}_{\hat\beta_2}=\frac{\frac{s_y}{s_x}\cdot\sqrt{1-r^2}}{\sqrt{n-2}}$$

* Teststatistik

$$t=\frac{\hat\beta_2-\beta_2}{\mbox{SE}_{\hat\beta_2}}$$
bzw. unter der Annahme, dass $H_0: \beta_2=0$  wahr ist: $t=\frac{\hat\beta_2}{\mbox{SE}_{\hat\beta_2}}$

`r fa('circle-right')``r fa('r-project')` ermittelt den p-Wert aus einer t-Verteilung mit $n-2$ Freiheitsgraden.
]
.panel[.panel-name[Warum t-verteilt?]
* Berechnung Regressionskoeffizient $\hat\beta_2$ mittels $\hat\beta_2 = \frac{s_{X, Y}}{s^2_X}$
* Die Kovarianz $(s_{X,Y})$ als Linearkombination zweier als normalverteilt angenommener Zufallsvariablen ist dabei normalverteilt (vgl. Annahmen)
* Die Varianz $(s^2_{X})$ ist unter Annahme normalverteilter Residuen (vgl. Annahmen) $\chi^2$-verteilt (Summe von quadrierten normalverteilten Zufallsvariablen).

* Ein Quotient aus einer standardnormalverteilten Zufallsgr√∂√üe im Z√§hler
und der Wurzel einer $\chi^2$-verteilten Gr√∂√üe geteilt durch die Freiheitsgrade im Nenner folgt einer t-Verteilung:

$$t=\frac{\hat\beta_2-\beta_2}{\mbox{SE}_{\hat\beta_2}} \sim t(n-2)$$
]
.panel[.panel-name[p-Wert]

```{r}
reg_auto %>% 
  get_regression_table() %>% 
  select(term,p_value) %>% gt()
```

* p-Wert als Wahrscheinlichkeit f√ºr das Auftreten des beobachteten Koeffizienten (`r round(obs_slope,2)`), wenn die Nullhypothese wahr ist. 

`r fa('circle-right')` im Beispiel ist der p-Wert quasi Null, der Steigungskoeffizient weicht damit mindestens auf dem 1%-Niveau signifikant von Null ab. 

]
]



???

`r fa('circle-right')``r fa('r-project')` Test zur √úberpr√ºfung, ob sich der Koeffizient signifikant von Null unterscheidet.

Here, our null hypothesis $H_0$ assumes that the population slope $\beta_2$ is 0. If the population slope $\beta_2$ is truly 0, then this is saying that there is no true relationship between teaching and "beauty" scores for all the instructors in our population. In other words, $x$= "beauty" score would have no associated effect on  
$y$=teaching score. The alternative hypothesis  
$H_A$, on the other hand, assumes that the population slope $\beta_2$ is not 0, meaning it could be either positive or negative. This suggests either a positive or negative relationship between teaching and "beauty" scores. 



* t im Auto-Beispiel: `r round(get_regression_table(reg_auto)$estimate[2],2)`/`r round(get_regression_table(reg_auto)$std_error[2],2)` $\approx$ `r round(get_regression_table(reg_auto)$estimate[2],2)/round(get_regression_table(reg_auto)$std_error[2],2)`

* Don‚Äôt worry if you‚Äôre feeling a little overwhelmed at this point. There is a lot of background theory to understand before you can fully make sense of the equations for theory-based methods. That being said, **theory-based methods and simulation-based methods** for constructing confidence intervals and conducting hypothesis tests **often yield consistent results**. 

vgl. moderndive [Abschnitt 10.5.1](https://moderndive.com/10-inference-for-regression.html#inference-conclusion)

* the standard error of $\hat\beta_2$ depends on
   * $\frac{s_x}{s_y}$: the relationship between the variability of the response variable and the variability of the explanatory variable . 
   * $\sqrt{1-r^2}$: Next, it looks into how the two variables relate to each other
   * Nenner $\sqrt{n-2}$: most important `r fa('circle-right')` as the sample size  
$n$ increases, the standard error $\mbox{SE}_{\hat\beta_2}$ decreases

* Just **as we demonstrated** in Subsection 7.3.3 when **using shovels** with $n = 25$, $50$, and $100$ slots, the **amount of sampling variation of the fitted slope $\hat\beta_2$ will depend on the sample size  
$n$

`r fa('circle-right')` **Zunehmende Reliabilit√§t (kleinerer Standardfehler) mit zunehmender Stichprobengr√∂√üe**



* First $s_x$ and $s_y$ are the sample standard deviations of the explanatory variable $Alter$ and the response variable $Preis$ respectively. 

* Second, $r$ is the sample correlation coefficient between $Preis$ and $Alter$. This was computed as `r cor(tbl_autos$Preis,tbl_autos$Alter)` 

* Lastly, $n$ is the number of pairs of points in the `tbl_autos` data frame, here: `r count(tbl_autos)`.



---
class: left

.blockquote[Koeffizienten und t-Test]

## Traditionelle Berechnung und Interpretation des Konfidenzintervalls

.panelset[
.panel[.panel-name[Vorgehen]
* Berechnung mit der Formel:

$$\hat\beta_2\pm t\cdot \mbox{SE}_{\hat\beta_2}$$

* Ermitlung des **t-Werts** unter Ber√ºcksichtigung...
  * ...des (grunds√§tzlich vor der Sch√§tzung der Parameterwerte) Konfidenzniveaus (bspw. 95%)
```{r}
sig <- .975 #obs! zweiseitiger Test
```
  * ...und der Freiheitsgrade (in der Einfachregression: $n-2$)
  
```{r}
df <- pull(count(tbl_autos))-2 # Freiheitsgrade
df
```
]
.panel[.panel-name[t-Wert in R]

```{r}
t <- qt(sig,df)
t
```

]
.panel[.panel-name[Konfidenzintervall in R]

```{r}
reg_auto %>% 
  get_regression_table() %>% 
  select(term,estimate,std_error) %>%
  filter(term=="Alter") %>% 
  summarise(ci_lo=estimate-t*std_error,
            ci_up=estimate+t*std_error) %>% gt()
```

Obs! Entspricht (erwartungsgem√§ss) nicht dem Konfidenzintervall aus dem Bootstrapping-Ansatz (ebenfalls Standardfehler-Ansatz)
]
.panel[.panel-name[Interpretation]
* **Exakt**: Bei wiederholter Stichprobenziehung (aus der Grundgesamtheit!) k√∂nnen wir erwarten, dass 95% der jeweiligen Konfidenzintervalle den  wahren Koeffizienten $\beta_2$ beinhalten. 

* Unser Konfidenzintervall f√ºr den Sch√§tzer $\hat\beta_2$ (`r lo_ci`; `r up_ci`)...
  * ...geh√∂rt entweder zu den 95% der Konfidenzintervalle, die den wahren Wert von $\beta_2$ umfassen, sodass dieser nicht Null sein kann.
  * ...oder es geh√∂rt zu den 5% der Konfidenzintervalle, die den wahren Wert nicht umfassen. Dann k√∂nnte $\beta_2$ mit geringer Wahrscheinlichkeit auch Null sein.
  
* Kurzform (**nicht exakt**): "Wir sind 95% "zuversichtlich" (*confident*), dass der wahre Koeffizient $\beta_2$ zwischen `r lo_ci` und  `r up_ci` liegt." (vgl. `r Cite(bib,"ismay_statistical_2024")`, Abschnitt 10.2.4)
]
]

???

In einem einfachen linearen Regressionsmodell sch√§tzen wir:

$\hat\beta_1$ (Achsenabschnitt / Intercept)

$\hat\beta_2$ (Steigung des Regressors X)

Das sind zwei Parameter, die aus den Daten gesch√§tzt werden. F√ºr jeden gesch√§tzten Parameter geht ein Freiheitsgrad verloren, da wir beim Sch√§tzen die Daten "gebraucht" haben.



---
class: left

.blockquote[Modellg√ºte und F-Test]

## Statistiken zur Beurteilung des Modells (Modellg√ºte)

```{r}
reg_auto %>% 
  get_regression_summaries() %>% 
  gt()
```

* (Angepasstes) Bestimmtheitsmass: Misst den Anteil der erkl√§rten Streuung $(R^2)$. $\mbox{adj.}~R^2$ ber√ºcksichtigt die Zahl der Regressoren. `r fa('circle-right')` Bei starker Abweichung von $(R^2)$ und $\mbox{adj.}~R^2$: Verdacht auf Overfitting

* MSE, RMSE und Sigma: kleine Werte bedeuten, dass die Modellvorhersagen gut sind

* Statistik und p-Wert: beziehen sich auf den F-Test, der pr√ºft, ob das Modell insgesamt signifikant besser ist als ein Modell ohne Pr√§diktoren.



???

* Modell ohne Pr√§diktoren w√§re hier einfach der Mittelwert als Sch√§tzer, statt des bedingten Mittelwerts.

* df: Freiheitsgrad des Regressors

* nobs: Anzahl Beobachtungen

Modellzusammenfassung
r.squared (Bestimmtheitsma√ü R¬≤)

üìå Allgemein: Anteil der Varianz der Zielvariable, der durch das Modell erkl√§rt wird.

üîç Interpretation: Nur 3.5% der Streuung in mpg kann durch den Pr√§diktor erkl√§rt werden ‚Äî sehr schwaches Modell.

adj.r.squared (korrigiertes R¬≤)

üìå Allgemein: Wie R¬≤, aber angepasst auf die Anzahl der Pr√§diktoren ‚Äî sch√ºtzt vor √úberanpassung.

üîç Interpretation: Bei 3.29‚ÄØ% liegt der bereinigte R¬≤ ‚Äî der Unterschied ist klein, da nur ein Pr√§diktor verwendet wird.

sigma (Residuen-Standardabweichung)

üìå Allgemein: Durchschnittliche Abweichung der tats√§chlichen Werte von den vorhergesagten.

üîç Interpretation: Die durchschnittliche Abweichung liegt bei ca. 0.535 Einheiten auf der Skala von mpg.

statistic (F-Wert)

üìå Allgemein: Testet, ob das Modell insgesamt signifikant besser ist als ein Modell ohne Pr√§diktoren.

üîç Interpretation: Der F-Wert von 16.7 deutet auf ein signifikantes Modell hin.

p.value (F-Test p-Wert)

üìå Allgemein: Wahrscheinlichkeit, dass das beobachtete Ergebnis rein zuf√§llig zustande kommt, wenn kein Effekt vorliegt.

üîç Interpretation: Mit p = 0.0000508 ist das Modell auf dem 0.1‚ÄØ%-Niveau hochsignifikant.

df (Freiheitsgrade f√ºr die Regression)

üìå Allgemein: Anzahl der erkl√§renden Variablen im Modell.

üîç Interpretation: Es wurde 1 Pr√§diktor verwendet.

logLik (Log-Likelihood)

üìå Allgemein: Ma√ü f√ºr die Modellg√ºte ‚Äì je h√∂her, desto besser (aber nur im Vergleich mit anderen Modellen sinnvoll).

üîç Interpretation: Log-Likelihood betr√§gt ‚Äì366, allein nicht aussagekr√§ftig.

AIC (Akaike Information Criterion)

üìå Allgemein: Modellg√ºte mit Strafterm f√ºr Modellkomplexit√§t ‚Äì niedrigere Werte sind besser.

üîç Interpretation: AIC von 738 kann mit anderen Modellen verglichen werden (z.‚ÄØB. mit mehreren Pr√§diktoren).

BIC (Bayesian Information Criterion)

üìå Allgemein: Wie AIC, aber st√§rkerer Strafterm f√ºr Komplexit√§t.

üîç Interpretation: BIC von 751 ist ebenfalls nur im Modellvergleich n√ºtzlich.

deviance (Residuenabweichung)

üìå Allgemein: Summe der quadrierten Abweichungen ‚Äì je kleiner, desto besser passt das Modell.

üîç Interpretation: Die Residuenabweichung betr√§gt 132.

df.residual (Freiheitsgrade der Residuen)

üìå Allgemein: Anzahl der Beobachtungen minus Anzahl der gesch√§tzten Parameter.

üîç Interpretation: 461 Freiheitsgrade ‚Äì deutet auf insgesamt 463 Beobachtungen hin.

nobs (Anzahl der Beobachtungen)

üìå Allgemein: Anzahl der in das Modell eingeflossenen Datenpunkte.

üîç Interpretation: Das Modell basiert auf 463 Beobachtungen.







---
class: left

.blockquote[Modellg√ºte und F-Test]

## Vorhersagequalit√§t: MSE und Co.

.panelset[
.panel[.panel-name[Vorhersagen & Residuen]
```{r}
reg_auto %>% 
  get_regression_points() %>% 
  head() %>% gt()
```
]
.panel[.panel-name[MSE]

* Mittlerer quadratischer Fehler (Mean Squared Error, MSE) als durchschnittlicher quadrierter Vorhersagefehler:

$$\mbox{MSE}=\frac{1}{n}\sum_{i=1}^n(y_i-\hat{y_i})^2$$
`r fa('circle-right')`Ein niedriger MSE bedeutet, dass das Modell die tats√§chlichen/gemessenen Werte sehr genau vorhersagt.

* Problem: MSE in quadratischen Einheiten (hier $\mbox{Geldeinheiten}^2$)
* L√∂sung: RSME als Wurzel des MSE
]
.panel[.panel-name[MSE in R]
```{r}
mse <- reg_auto %>% 
          get_regression_points() %>% 
          summarise(RSS=sum(residual^2),
                    MSE=1/n()*RSS)
mse
```
 
```{r}
rsme <- sqrt(pull(mse))
rsme
```


]
.panel[.panel-name[Sigma]


* $\sigma$: Standardabweichung der Residuen:

$$\sigma=\sqrt{\frac{\mbox{RSS}}{n-p}}$$


```{r}
sigma <- sqrt(mse$RSS/(df))
sigma
```

]
]

???

Obs! Werte stimmen mit den Werten aus der `get_regression_summaries()`-Tabelle √ºberein



---
class: left

.blockquote[Modellg√ºte und F-Test]

## F-Test auf gemeinsame Signifikanz der Regressoren

.panelset[
.panel[.panel-name[F-Test]
* Ziel: √úberpr√ºfung, ob das Regressionsmodell insgesamt eine signifikante Erkl√§rungskraft hat.

* Referenz: Nullmodell (`r fa('circle-right')`einfacher arithmetischer Mittelwert)

* Hypothesen des F-Tests:
  - Nullhypothese: Alle Regressionskoeffizienten (au√üer dem Interzept) sind gleich Null.
  
$$H_0: \beta_1 = \beta_2 = \dots = \beta_p = 0$$
  
  - Alternativhypothese: Mindestens einer der Regressoren hat einen signifikanten Einfluss.

$$H_A: \text{Mindestens ein } \beta_i \neq 0$$
]
.panel[.panel-name[F-Wert]
* Der **F-Wert** wird aus der **Modellg√ºte** und dem **Fehlermodell** berechnet:
  - **Modellg√ºte**: durch das Modell erkl√§rte Variation (Regression).
  - **Fehlermodell**: nicht durch das Modell erkl√§rte Variation (Fehler).


$$F = \frac{\text{Erkl√§rte Variation (Modell)}}{\text{Nicht erkl√§rte Variation (Fehler)}} = \frac{\frac{SS_{\text{reg}}}{p}}{\frac{SS_{\text{res}}}{n - p - 1}}$$

* Interpretation:
  - **H√∂herer F-Wert**: Hinweis auf ein besseres Modell.
  - **Kleiner F-Wert**: Das Modell erkl√§rt wenig der Variation der Zielgr√∂√üe.
]
.panel[.panel-name[p-Wert]

* Vergleich des p-Werts zum F-Test mit dem kritischen Wert:
  * p-Wert < kritischer Wert bedeutet, dass mindestens ein Regressor einen Einfluss hat... 
  * und das Modell somit einen signifikant h√∂heren Erkl√§rungswert hat als das Nullmodell

* Auto-Beispiel: Der p-Wert von `r get_regression_summaries(reg_auto)$p_value` deutet darauf hin, dass das Modell mindestens auf dem 1%-Niveau einen signifikanten Erkl√§rungswert gegen√ºber dem Nullmodell hat.

]
]



???

* Refresher: Regression dient der Ermittlung bedingter Mittelwerte

* Referenz des F-Tests also: unbedingter Mittelwert (der abh√§ngigen Variable)

Mit anderen Worten: Liege ich beim Sch√§tzen im Durchschnitt besser, wenn ich einfach den Mittelwert (hier: `r mean(tbl_autos$Preis)` Euro) der abh√§ngigen Variablen tippe?



---
class: left

.blockquote[Modellauswahl]

## Schrittweise Selektion

.panelset[
.panel[.panel-name[Alternativen]
* R√ºckw√§rts-Eliminierung: 
  * Beginn mit einem Modell, das alle potenziellen Regressoren enth√§lt
  * Schrittweise Eliminierung einzelner Regressoren,...
  * ...bis der Erkl√§rungswert des Modells nicht mehr verbessert werden kann
* Vorw√§rts-Auswahl: 
  * Beginn mit einem Modell, das nur einen Regressor enth√§lt
  * Schrittweises Hinzuf√ºgen einzelner Regressoren,...
  * ...bis der Erkl√§rungswert des Modells nicht mehr verbessert werden kann
* H√§ufig genutztes Kriterien f√ºr den Erkl√§rungswert (vgl. `r Cite(bib,"crh_intro_2024")`): $\mbox{adj.}~R^2$ als Kriterium
* Ausserdem: Kriterium der Sparsamkeit (Parsimony)
]
.panel[.panel-name[Beispiel]

* Alter und Fahrleistung (km) als Regressoren

$$\begin{eqnarray}
\widehat{\mbox{Preis}}&=&\hat\beta_1 + \hat\beta_2\cdot \mbox{Alter} + \hat\beta_3\cdot \mbox{km}\\
\end{eqnarray}$$

```{r}
reg_auto2 <- tbl_autos %>%
                  lm(Preis~Alter+km,.)
```

]
.panel[.panel-name[Koeffizienten]

```{r}
reg_auto2 %>%
  get_regression_table() %>% gt()
```
]
.panel[.panel-name[Modell]

```{r}
reg_auto %>%
  get_regression_summaries() %>% gt()
```

```{r}
reg_auto2 %>%
  get_regression_summaries() %>% gt()
```

`r fa('question-circle')` Gibt es einen Mehrwert, des erweiterten Modells? Welches Modell sollte gew√§hlt werden?
]
]


???

* Kriterium der Sparsamkeit: Parsimony

---
class: left

.blockquote[Modellauswahl]

## Multikolinearit√§t

* In Modellen mit mehreren Regressoren kann das Problem der Multikollinearit√§t auftreten.

* Multikollinearit√§t als (nahezu) lineare Abh√§ngigkeit zwischen zwei oder mehr Regressoren.

* Folge: gr√∂√üere Standardfehler, unsichere Sch√§tzungen (aber keine systematische Verzerrung!)


| Problem                           | F√ºhrt zu verzerrten Sch√§tzern? | Ursache                                  |
|----------------------------------|-------------------------------|-------------------------------------------|
| **Endogenit√§t / Identifikationsproblem** | ‚úÖ Ja                        | Korrelation zwischen Regressor und Fehlerterm |
| **Multikollinearit√§t**           | ‚ùå Nein (aber hohe Varianz)    | Lineare Abh√§ngigkeit zwischen Regressoren     |

???

Multikollinearit√§t betrifft nicht die G√ºltigkeit der Inferenz im engeren Sinne, sondern ihre Zuverl√§ssigkeit
Die genannten vier Annahmen (Linearit√§t, Unabh√§ngigkeit, Normalverteilung, Homoskedastizit√§t) sichern ab, dass die Sch√§tzer unverzerrt und die Tests korrekt sind.

Multikollinearit√§t verletzt keine dieser vier Annahmen direkt.
* Aber: Sie f√ºhrt dazu, dass Standardfehler der Koeffizienten gro√ü werden, was zu unsicheren Sch√§tzungen und breiten Konfidenzintervallen f√ºhrt. * Deshalb ist Inferenz formal noch g√ºltig, aber praktisch oft wenig aussagekr√§ftig.


---
class: left

.blockquote[Modellauswahl]

## √úberpr√ºfung auf Multikolinearit√§t

.panelset[
.panel[.panel-name[Korrelation]

```{r}
tbl_autos %>%
  summarise(r_XY=cor(Alter,km))
```

`r fa('circle-right')` sehr hoher Wert (Anfangsverdacht, aber keine hinreichende Bedingung!)
]
.panel[.panel-name[VIF]
* Varianzinflation (Variance Inflation Factor, VIF)
```{r}
car::vif(reg_auto2)
```
  * Faustregel: 
    * VIF < 5: unproblematisch
    * VIF > 5: Vorsicht geboten
    * VIF > 10: Problematisch

]
]


???

* Obwohl Alter und Kilometerstand korreliert sind (cor = 0.80), bleibt die Multikollinearit√§t beherrschbar.
Die Sch√§tzer bleiben stabil und interpretierbar.

* Bei problematischen VIF-Werten: bspw. L√∂sung durch **Hauptkomponentenanalyse** und Verwendung der Hauptkomponenten als Regressoren (`r fa('circle-right')` Verweis auf ER017)




---
class: inverse, center, middle

## Regressionsdiagnostik im traditionellen Ansatz

.blockquote[Annahmen f√ºr valide Inferenz]

.blockquote[Ausblick: BLUE-Eigenschaft]


---
class: left

.blockquote[Annahmen f√ºr valide Inferenz]

## Regressionsdiagnostik zur √úberpr√ºfung kritischer Annahmen


.panelset[
.panel[.panel-name[Annahmen]
* Linearit√§t: Es besteht ein linearer Zusammenhang zwischen Pr√§diktoren und der Zielvariablen. 

* Unabh√§ngigkeit: Residuen sind nicht systematisch voneinander abh√§ngig (z.B. bei Zeitreihen).

* Normalverteilung: Die Residuen sind (ann√§hernd) normalverteilt.

* Homoskedastizit√§t: Die Varianz der Residuen ist √ºber alle Werte von $\hat{y}$ konstant.

]
.panel[.panel-name[Visualisierung]
* Mit dem **ggfortify**-Paket k√∂nnen vier Plots zur Regressionsdiagnostik in einer Zeile erzeugt werden:

```{r}
#| echo: false
#| message: false
#| out-width: '35%'
#| fig-align: 'center'
library(ggfortify)
p_diag <- autoplot(reg_auto)
p_diag
```

* Interpretationen zu den Plots auf den folgenden Folien

]
]


---
class: left

.blockquote[Annahmen f√ºr valide Inferenz]

## √úberpr√ºfung der Linearit√§ts-Annahme

.panelset[
.panel[.panel-name[Beispiel]

```{r}
#| echo: true
#| message: false
#| out-width: '35%'
#| fig-align: 'center'
tbl_autos %>% 
          ggplot(aes(x=Alter,y=Preis)) + 
              geom_point(alpha=.5,size=.8) + theme_light() + 
              geom_smooth(method = "lm", se = FALSE) 
```

]
.panel[.panel-name[Visuelle Inspektion]
```{r}
#| echo: true
#| message: false
#| out-width: '30%'
#| fig-align: 'center'
library(ggfortify)
autoplot(reg_auto2, which = 1)
```

* Interpretation:
  * Punkte sollten zuf√§llig um die Nulllinie streuen `r fa('circle-right')` Linearit√§t erf√ºllt
  * Systematische Muster `r fa('circle-right')` Hinweis auf nichtlineare Zusammenh√§nge
]
]

???

Interpretation der visuellen Inspektion:
* Streudiagramm: Residuen vs. Vorhersagewerte
* Ziel: Kein systematisches Muster, zuf√§llige Streuung um die Nulllinie
* Kurven oder Muster deuten auf Verletzung der Linearit√§t hin




---
class: left

.blockquote[Annahmen f√ºr valide Inferenz]

## Beispiel f√ºr Verletzung der Linearit√§ts-Annahme
```{r}
#| echo: false
#| message: false
#| out-width: '75%'
#| fig-align: 'center'
knitr::include_graphics('https://moderndive.com/ModernDive_files/figure-html/non-linear-1.png')
```

.quelle[Quelle: `r Cite(bib,"ismay_statistical_2024")`]
  



---
class: left

.blockquote[Annahmen f√ºr valide Inferenz]

## Unabh√§ngigkeit der Residuen

.panelset[
.panel[.panel-name[Visuell]
* Autokorrelationsplot der Residuen
```{r}
#| echo: false
#| message: false
#| out-width: '35%'
#| fig-align: 'center'
autoplot(reg_auto, which = 3)  # 
```

* Interpretation: systematische Muster in den Residuen gibt, die auf eine Verletzung der Unabh√§ngigkeit hinweisen
]
.panel[.panel-name[Test]

* Durbin-Watson-Test f√ºr Autokorrelation

```{r}
#| message: false
#| warning: false
library(lmtest)
dwtest(reg_auto)
```

Interpretation: Ein Wert nahe 2 deutet darauf hin, dass keine Autokorrelation vorliegt. Werte deutlich unter oder √ºber 2 deuten auf Abh√§ngigkeiten hin.
]
]


???

* Durbin-Watson: $H_0$ (keine Autokorrelation)...
* ...kann beim hohen p-Wert = 0.9982 nicht abgelehnt werden kann. 

`r fa('circle-right')` Dies bedeutet, dass keine signifikante Autokorrelation der Residuen existiert.

---
class: left

.blockquote[Annahmen f√ºr valide Inferenz]

## Normalverteilung der Residuen

.panelset[
.panel[.panel-name[Visuell]
* Quantile-Quantile-Plot (QQ-Plot)
```{r}
#| echo: false
#| message: false
#| out-width: '35%'
#| fig-align: 'center'
autoplot(reg_auto, which = 2)   
```

Interpretation: Abweichungen vom Diagonalstrich deuten auf Abweichungen von der Normalverteilung hin.
]
.panel[.panel-name[Test]

* Shapiro-Wilk-Test auf Normalverteilung

```{r}
shapiro.test(residuals(reg_auto))
```
* Shapiro-Wilk $H_0$ (Normalverteilung der Residuen)...
* kann beim hohen p-Wert = 0.44 nicht abgelehnt werden kann. 
]
]

???

Interpretation: Der Q-Q-Plot zeigt, ob die Residuen ungef√§hr einer Normalverteilung folgen. Abweichungen vom Diagonalstrich deuten auf Abweichungen von der Normalverteilung hin.

W = 0.97287: Keine signifikante Abweichung von der Normalverteilung.

p-Wert = 0.4416: Nullhypothese (Normalverteilung) wird nicht abgelehnt.

Ergebnis: Residuen sind normalverteilt und erf√ºllen die Annahme der Normalverteilung.



---
class: left

.blockquote[Annahmen f√ºr valide Inferenz]

## Homoskedastizit√§t

.panelset[
.panel[.panel-name[Visuell]
* Residuen vs. Vorhersage
```{r}
#| echo: false
#| message: false
#| out-width: '35%'
#| fig-align: 'center'
autoplot(reg_auto, which = 1)   
```

Interpretation: Wenn die Residuen keine erkennbare Struktur (bspw. Trichterform) aufweisen , spricht dies f√ºr Homoskedastizit√§t.
]
.panel[.panel-name[Test]

* Breusch-Pagan-Test f√ºr Homoskedastizit√§t

```{r}
bptest(reg_auto)
```
* Breusch-Pagan $H_0$ (Homoskedastizit√§t liegt vor)...
* kann beim hohen p-Wert = 0.28 nicht abgelehnt werden kann. 
]
]

???

* BP = 1.1565: Teststatistik.
* p-Wert = 0.2822: Keine Heteroskedastizit√§t festgestellt.
* Ergebnis: Die Annahme der Homoskedastizit√§t ist erf√ºllt.


---
class: left

## Exkurs: Ausreisser-Diagnostik

* Der vierte Plot aus `autoplot(reg_auto)` (sog. Leverage-Plot) wurde bisher nicht genutzt. 

```{r}
#| echo: false
#| message: false
#| out-width: '35%'
#| fig-align: 'center'
autoplot(reg_auto, which = 4)
```

* Beobachtungen, die au√üerhalb der gestrichelten Linien (die Schwellenwerte f√ºr Einfluss) liegen, haben einen gro√üen Einfluss auf das Modell und sollten √ºberpr√ºft werden.

* Hohe Werte in Cook's Distance (Ordinate) oder Leverage zeigen potenziell problematische Punkte, die die Modellg√ºte verf√§lschen k√∂nnten.


---
class: inverse,center,middle

## Ausblick


.blockquote[Multiple Regression und BLUE-Eigenschaften]

.blockquote[Logistische Regression]


---
class: left

.blockquote[Multiple Regression und BLUE-Eigenschaften]

## BLUE-Eigenschaft (Best Linear Unbiased Estimator)

* In der multiplen Regression kann Multikollinearit√§t auftreten und zu instabilen Sch√§tzungen und erh√∂hten Standardfehlern f√ºhren.

* Unter den Annahmen der klassischen linearen Regression (Linearit√§t, Unabh√§ngigkeit der Fehler, Homoskedastizit√§t, Normalverteilung der Fehler) sind OLS-Sch√§tzer BLUE (**B**est, **L**inear **U**nbiased **E**stimator)

`r fa('circle-right')` OLS-Sch√§tzer sind unter den o.a. Annahmen bestm√∂gliche unverzerrte Sch√§tzer  $(E[\hat{\beta}] = \beta )$ mit den geringsten Standardfehlern.

* vgl. dazu ausf√ºhrlich `r Cite(bib,"vonAuer_oekonometrie_2023")`


???

(und damit h√∂chste Pr√§zision innerhalb der Klasse der validen Sch√§tzer)

---
class: left

.blockquote[Logistische Regression]

## Bin√§rer statt numerischer Regressand

* In der Praxis interessiert h√§ufig die Vorhersage bin√§rer Ergebnisse:
   * bspw. Klassifikation von E-Mails in "Spam" oder "Nicht-Spam"
   * Vorhersage von Kaufentscheidungen ("Kauf" oder "Nicht-Kauf")

* Bei bin√§ren abh√§ngigen Variablen (z.B. Ja/Nein) kann die lineare Regression nicht angewendet werden, da die Vorhersage au√üerhalb des Intervalls [0, 1] liegen kann.

* L√∂sung: logistische Regression auf Basis einer logistischen Funktion
‚Å°



---
class: inverse,center,middle

# Sch√∂nen Feierabend.

---

background-image: url("http://bit.ly/cs631-donkey")
background-size: 80%





---
class: left

## Quellenverzeichnis

.ref-slide[
```{r, results='asis', echo=FALSE, warning=FALSE}
PrintBibliography(bib)
```
]
