---
title: "A/B Test Analyse: E-Commerce Checkout-Optimierung"
author: "Datenanalyse"
date: "`r Sys.Date()`"
format:
  html:
    theme: cosmo
    toc: true
    toc-depth: 2
    code-fold: true
    code-summary: "Code anzeigen"
    embed-resources: true
execute:
  warning: false
  message: false
---

```{r setup}
library(tidyverse)
library(rstatix)
library(effectsize)
library(knitr)
library(kableExtra)
library(scales)
```

## Hintergrund

### Problemstellung

Ein E-Commerce-Unternehmen m√∂chte den durchschnittlichen Bestellwert (Average Order Value, AOV) erh√∂hen. Dazu wurde ein neues Checkout-Design mit 1-Click-Upsells entwickelt, das relevante Zusatzprodukte im letzten Schritt des Kaufprozesses anbietet.

### Experimentdesign

- **Control Group**: Altes Checkout-Design (N = 50.000 Kunden)
- **Test Group**: Neues Checkout-Design mit 1-Click-Upsells (N = 50.000 Kunden)
- **Zielmetrik**: Durchschnittlicher Bestellwert in Euro
- **Randomisierung**: Kunden wurden zuf√§llig einer der beiden Gruppen zugewiesen
- **Zeitraum**: 4 Wochen paralleler Test

**Forschungsfrage**: Erh√∂ht das neue Design den durchschnittlichen Bestellwert signifikant?

**Null-Hypothese (H‚ÇÄ)**: Es gibt keinen Unterschied im durchschnittlichen Bestellwert zwischen den Gruppen (Œº‚ÇÅ = Œº‚ÇÇ)

**Alternativ-Hypothese (H‚ÇÅ)**: Das neue Design erh√∂ht den durchschnittlichen Bestellwert (Œº‚ÇÅ < Œº‚ÇÇ)

## Daten generieren

```{r data-generation}
set.seed(42)

# Simulierte Bestellwerte basierend auf historischen Daten
# Control: Œº = 85‚Ç¨, œÉ = 25‚Ç¨
# Test: Œº = 92‚Ç¨, œÉ = 25‚Ç¨ (Erwartete Steigerung durch Upsells)

ab_test_data <- tibble(
  group = c(
    rep("Control", 50000),
    rep("Test", 50000)
  ),
  order_value = c(
    rnorm(50000, mean = 85, sd = 25),  # Control: √ò 85‚Ç¨
    rnorm(50000, mean = 92, sd = 25)   # Test: √ò 92‚Ç¨ (+8%)
  )
) %>%
  # Realistische Constraints: Keine negativen Werte, max 500‚Ç¨
  # (Mindestbestellwert 5‚Ç¨, sehr gro√üe Bestellungen > 500‚Ç¨ sind Ausnahmen)
  mutate(order_value = pmax(5, pmin(500, order_value)))
```

:::{.callout-note}
## Datengenerierung

Die Daten werden hier simuliert, um das Analyseverfahren zu demonstrieren. In der Praxis w√ºrden die tats√§chlichen Bestelldaten aus dem Tracking-System verwendet. Die Normalverteilung mit Œº = 85‚Ç¨ und œÉ = 25‚Ç¨ entspricht typischen E-Commerce-Mustern.
:::

## Deskriptive Statistiken

```{r summary-stats}
summary_stats <- ab_test_data %>%
  group_by(group) %>%
  summarise(
    N = comma(n()),
    `Mean (‚Ç¨)` = round(mean(order_value), 2),
    `Median (‚Ç¨)` = round(median(order_value), 2),
    `SD (‚Ç¨)` = round(sd(order_value), 2),
    `Min (‚Ç¨)` = round(min(order_value), 2),
    `Max (‚Ç¨)` = round(max(order_value), 2),
    .groups = "drop"
  )

summary_stats %>%
  kable(align = "lrrrrrr") %>%
  kable_styling(
    bootstrap_options = c("striped", "hover"),
    full_width = FALSE
  )
```

**Mittelwert-Differenz**: `r round(diff(summary_stats$"Mean (‚Ç¨)"), 2)` ‚Ç¨ 
(+`r round(abs(diff(summary_stats$"Mean (‚Ç¨)")) / summary_stats$"Mean (‚Ç¨)"[1] * 100, 1)`%)

## Statistische Tests

### Wahl der Testmethode

F√ºr diesen A/B-Test verwenden wir den **Welch Two Sample t-Test**.

**Warum t-Test?**

- Wir vergleichen die Mittelwerte zweier unabh√§ngiger Gruppen
- Die Zielmetrik (Bestellwert) ist kontinuierlich und ann√§hernd normalverteilt
- Gro√üe Stichprobe (N = 50.000 pro Gruppe) ‚Üí Zentraler Grenzwertsatz gilt

**Warum Welch-Variante (statt Student's t-Test)?**

- **Keine Annahme gleicher Varianzen** erforderlich (robuster)
- Selbst bei gleichen Varianzen liefert Welch's Test korrekte Ergebnisse
- In der Praxis sind Varianzen selten exakt gleich
- **Best Practice** f√ºr A/B-Tests: "Always use Welch" (Student's t-Test nur wenn Varianzhomogenit√§t nachgewiesen)

**Warum nicht Mann-Whitney-U-Test?**

- Bei N > 10.000 ist der t-Test robust gegen Verletzungen der Normalverteilung
- t-Test hat h√∂here statistische Power bei normalverteilten Daten
- Mann-Whitney w√§re nur bei stark schiefen Verteilungen oder Ausrei√üern besser

**Warum nicht Bayesianischer Test?**

- Frequentistische Tests sind Standard in der Industrie (bessere Kommunizierbarkeit)
- Bei gro√üen Stichproben liefern beide Ans√§tze √§hnliche Ergebnisse
- Bayesianische Tests sind n√ºtzlich bei kleinen N oder Prior-Knowledge

```{r statistical-tests}
# T-Test durchf√ºhren
t_test_result <- ab_test_data %>%
  t_test(order_value ~ group, detailed = TRUE)

# Cohen's d berechnen - separate Vektoren erstellen
control_data <- ab_test_data %>% filter(group == "Control") %>% pull(order_value)
test_data <- ab_test_data %>% filter(group == "Test") %>% pull(order_value)

cohens_result <- cohens_d(control_data, test_data, pooled_sd = TRUE)

# Ergebnisse kombinieren
test_results <- tibble(
  Test = "Welch Two Sample t-test",
  `t-statistic` = round(t_test_result$statistic, 2),
  `df` = comma(round(t_test_result$df, 0)),
  `p-value` = format.pval(t_test_result$p, eps = 0.001, digits = 3),
  `Cohen's d` = round(cohens_result$Cohens_d, 3),
  Interpretation = cohens_result$magnitude
)

test_results %>%
  kable() %>%
  kable_styling(
    bootstrap_options = c("striped", "hover"),
    full_width = FALSE
  )
```

## Visualisierung

### Verteilungsvergleich

```{r plot-distribution, fig.width=10, fig.height=6}
ab_test_data %>%
  ggplot(aes(x = group, y = order_value, fill = group)) +
  geom_violin(alpha = 0.5, trim = FALSE) +
  geom_boxplot(width = 0.2, alpha = 0.7, outlier.alpha = 0.3) +
  stat_summary(
    fun = mean, 
    geom = "point", 
    size = 4, 
    color = "red",
    shape = 18
  ) +
  stat_summary(
    fun = mean,
    geom = "text",
    aes(label = sprintf("%.2f ‚Ç¨", after_stat(y))),
    vjust = -1.5,
    color = "red",
    fontface = "bold"
  ) +
  scale_fill_brewer(palette = "Set2") +
  scale_y_continuous(labels = label_dollar(prefix = "", suffix = " ‚Ç¨")) +
  labs(
    title = "Vergleich des durchschnittlichen Bestellwerts",
    subtitle = sprintf(
      "Cohen's d = %.3f (%s) | p < 0.001", 
      cohens_result$Cohens_d, 
      cohens_result$magnitude
    ),
    x = "Gruppe",
    y = "Bestellwert (‚Ç¨)",
    caption = "Rote Rauten zeigen Mittelwerte"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(color = "gray40")
  )
```

### Dichteverteilung

```{r plot-density, fig.width=10, fig.height=5}
ab_test_data %>%
  ggplot(aes(x = order_value, fill = group)) +
  geom_density(alpha = 0.6) +
  geom_vline(
    data = summary_stats,
    aes(xintercept = `Mean (‚Ç¨)`, color = group),
    linetype = "dashed",
    linewidth = 1
  ) +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2") +
  scale_x_continuous(labels = label_dollar(prefix = "", suffix = " ‚Ç¨")) +
  labs(
    title = "Dichteverteilung der Bestellwerte",
    x = "Bestellwert (‚Ç¨)",
    y = "Dichte",
    fill = "Gruppe",
    color = "Mittelwert"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(face = "bold", size = 16)
  )
```

## Business Impact

### Hochrechnung auf Jahresumsatz

Um die praktische Bedeutung des Effekts zu quantifizieren, rechnen wir den Unterschied auf den erwarteten Jahresumsatz hoch. Diese Betrachtung ist entscheidend f√ºr die ROI-Bewertung der Optimierungsma√ünahme.

```{r business-impact}
# Berechnungen f√ºr Business Impact
control_mean <- summary_stats$`Mean (‚Ç¨)`[summary_stats$group == "Control"]
test_mean <- summary_stats$`Mean (‚Ç¨)`[summary_stats$group == "Test"]
lift_absolute <- test_mean - control_mean
lift_percent <- (lift_absolute / control_mean) * 100

# Hochrechnung auf erwartete Jahreszahlen
# Test lief 4 Wochen mit 100.000 Bestellungen ‚Üí ~1,3 Mio Bestellungen/Jahr
test_period_weeks <- 4
weeks_per_year <- 52
orders_in_test <- 100000
annual_orders <- (orders_in_test / test_period_weeks) * weeks_per_year

# Umsatzberechnung
test_revenue <- test_mean * orders_in_test
control_revenue <- control_mean * orders_in_test
test_period_lift <- test_revenue - control_revenue

annual_revenue_test <- test_mean * annual_orders
annual_revenue_control <- control_mean * annual_orders
annual_lift <- annual_revenue_test - annual_revenue_control

impact_table <- tibble(
  Metrik = c(
    "Durchschnittlicher Bestellwert (Control)",
    "Durchschnittlicher Bestellwert (Test)",
    "Absolute Steigerung pro Bestellung",
    "Relative Steigerung",
    "",
    "Bestellungen im 4-Wochen-Test",
    "Zus√§tzlicher Umsatz im Test (4 Wochen)",
    "",
    "Hochrechnung auf Jahresbasis:",
    "Erwartete Bestellungen pro Jahr",
    "Jahresumsatz (bei altem Design)",
    "Jahresumsatz (bei neuem Design)",
    "Zus√§tzlicher Jahresumsatz"
  ),
  Wert = c(
    sprintf("%.2f ‚Ç¨", control_mean),
    sprintf("%.2f ‚Ç¨", test_mean),
    sprintf("%.2f ‚Ç¨", lift_absolute),
    sprintf("%.1f%%", lift_percent),
    "",
    sprintf("%s", comma(orders_in_test)),
    sprintf("%s ‚Ç¨", comma(test_period_lift)),
    "",
    "",
    sprintf("%s", comma(round(annual_orders))),
    sprintf("%s ‚Ç¨", comma(round(annual_revenue_control))),
    sprintf("%s ‚Ç¨", comma(round(annual_revenue_test))),
    sprintf("%s ‚Ç¨", comma(round(annual_lift)))
  )
)

impact_table %>%
  kable() %>%
  kable_styling(
    bootstrap_options = c("striped", "hover"),
    full_width = FALSE
  ) %>%
  row_spec(7, bold = TRUE, background = "#fff3cd") %>%
  row_spec(13, bold = TRUE, background = "#e8f4f8")
```

## Interpretation & Fazit

```{r calc-for-interpretation, include=FALSE}
# Berechnungen f√ºr Inline-Verwendung
mean_diff <- abs(diff(summary_stats$`Mean (‚Ç¨)`))
p_val <- t_test_result$p
cohens_d <- cohens_result$Cohens_d
magnitude <- cohens_result$magnitude
```

### Statistische Signifikanz

‚úÖ **Statistisch hochsignifikant** (p < 0.001)

Mit N = 100.000 Beobachtungen zeigt der t-Test einen t-Wert von `r round(t_test_result$statistic, 2)` bei einem p-Wert < 0.001. Der Unterschied ist statistisch eindeutig nachweisbar.

### Praktische Relevanz

- **Absolute Differenz**: `r sprintf("%.2f ‚Ç¨", mean_diff)` pro Bestellung
- **Relative Steigerung**: +`r sprintf("%.1f%%", lift_percent)`
- **Cohen's d**: `r round(cohens_d, 3)`

‚úÖ **Small to Medium Effect Size** - Praktisch relevant!

**Bewertung**: Mit einem Cohen's d von `r round(cohens_d, 3)` liegt ein kleiner bis mittlerer Effekt vor, der im E-Commerce-Kontext **hochrelevant** ist. Eine Steigerung von `r sprintf("%.1f%%", lift_percent)` beim durchschnittlichen Bestellwert hat erhebliche finanzielle Auswirkungen.

### Key Takeaways

:::{.callout-important}
## Wichtigste Ergebnisse

1. **Statistisch und praktisch signifikant**: Der Test zeigt sowohl statistische Signifikanz als auch praktische Relevanz

2. **Effect Size**: Cohen's d von `r round(cohens_d, 3)` entspricht einem kleinen bis mittleren Effekt - im E-Commerce ein substanzieller Erfolg

3. **Business Impact**: Bei 100.000 Bestellungen w√§hrend des 4-Wochen-Tests entspricht dies einem zus√§tzlichen Umsatz von **`r comma(round(test_period_lift))` ‚Ç¨**. Hochgerechnet auf ein Jahr (~1,3 Mio Bestellungen) ergibt sich ein Potenzial von **`r comma(round(annual_lift))` ‚Ç¨**

4. **ROI-Perspektive**: Selbst wenn die Implementierung 50.000‚Ç¨ gekostet h√§tte, w√ºrde sich die Investition bereits im ersten Jahr amortisieren
:::

### Handlungsempfehlung

Basierend auf dieser Analyse:

- ‚úÖ **Rollout empfohlen**: Das neue Checkout-Design sollte f√ºr alle Kunden ausgerollt werden
- ‚úÖ **Quick Win**: Die Verbesserung ist signifikant und sofort umsetzbar
- üìä **Monitoring**: Langfristige √úberwachung der Metriken zur Validierung des Effekts
- üîç **Weitere Optimierung**: Analyse, welche Upsells am besten funktionieren

:::{.callout-tip}
## N√§chste Schritte

1. Segmentanalyse durchf√ºhren (unterschiedliche Effekte nach Produktkategorie?)
2. Conversion Rate parallel analysieren (kein Trade-off?)
3. Langzeit-Kohorten-Analyse (6-12 Monate)
:::

## Methodische Hinweise

### Verwendete statistische Verfahren

**Welch Two Sample t-Test**

- Pr√ºft, ob sich die Mittelwerte zweier unabh√§ngiger Gruppen signifikant unterscheiden
- Verwendet die Satterthwaite-Approximation f√ºr die Freiheitsgrade
- Annahmen: Unabh√§ngige Beobachtungen, ann√§hernde Normalverteilung (bei gro√üem N nicht kritisch)
- Keine Annahme gleicher Varianzen n√∂tig (im Gegensatz zu Student's t-Test)

**Cohen's d (Effect Size)**

- Standardisierte Mittelwertsdifferenz: d = (Œº‚ÇÅ - Œº‚ÇÇ) / œÉ_pooled
- Unabh√§ngig von Stichprobengr√∂√üe und Ma√üeinheit
- Erm√∂glicht Vergleich √ºber verschiedene Studien hinweg
- Berechnung mit pooled standard deviation f√ºr zwei Gruppen

**Warum beides wichtig ist:**

- **p-Wert**: Beantwortet "Ist der Effekt real?" (statistische Signifikanz)
- **Effect Size**: Beantwortet "Wie gro√ü ist der Effekt?" (praktische Relevanz)
- Bei gro√üem N sind auch winzige Effekte signifikant ‚Üí Effect Size ist entscheidend!

### Interpretation nach Cohen (1988)

- |d| < 0.2: negligible (vernachl√§ssigbar)
- 0.2 ‚â§ |d| < 0.5: small (klein)
- 0.5 ‚â§ |d| < 0.8: medium (mittel)
- |d| ‚â• 0.8: large (gro√ü)

**Wichtig**: Diese Grenzen sind Richtwerte. Die praktische Relevanz h√§ngt stark vom Kontext ab. Im E-Commerce kann bereits ein "small" Effect eine gro√üe finanzielle Wirkung haben!

:::{.callout-note}
## Reproduzierbarkeit

Dieser Report verwendet `set.seed(42)` f√ºr reproduzierbare Ergebnisse. Die Daten simulieren realistische E-Commerce-Bestellwerte mit Normalverteilung und Constraints (5‚Ç¨ - 500‚Ç¨).
:::
